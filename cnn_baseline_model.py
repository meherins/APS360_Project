# -*- coding: utf-8 -*-
"""CNN baseline model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lM50psDLu6ucscLzDgNQFOAUx_pGGpcO

# import & mount
"""

import matplotlib
import matplotlib.pyplot as plt  # Most common visualization package that a lot of others are based on

import numpy as np  # Common package for numerical methods
import pandas as pd  # Common package for data storeage/manipulation
import seaborn as sns  # Common package for statistical visualizations
import datetime

# from IPython.display import SVG
# from graphviz import Source

# Import useful packages from sklearn
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
from sklearn.linear_model import LogisticRegressionCV
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier

# Torch and Time!
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms

# Import portion of a package
import scipy.stats as stats
from sklearn.impute import SimpleImputer as Imputer  # Specific function from common machine learning package

from PIL import ImageFile

import torchvision.models
alexnet = torchvision.models.alexnet(pretrained=True)
import os

"""# New Section"""


"""#CNN

"""

import math
class CNetwork(nn.Module):
    def __init__(self, kernel_sizes = [3, 5, 7]):
        super(CNetwork, self).__init__()
        self.name = "CNN"
        self.conv1 = nn.Conv2d(3, 5, kernel_sizes[0])
        self.conv2 = nn.Conv2d(5, 10, kernel_sizes[1])
        self.conv3 = nn.Conv2d(10, 25, kernel_sizes[2])

        self.pool = nn.MaxPool2d(2, 2)

        # fully connected layers
        self.fc_1 = math.floor((224 - kernel_sizes[0] + 1)/2)
        self.fc_2 = math.floor((self.fc_1 - kernel_sizes[1] + 1)/2)
        self.fc_3 = math.floor((self.fc_2 - kernel_sizes[2] + 1)/2)
        self.fc = 25*self.fc_3**2

        self.fc1 = nn.Linear(self.fc, 120)
        self.fc2 = nn.Linear(120, 60)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = x.view(-1, self.fc)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        x = x.squeeze(1) # Flatten to [batch_size]
        #x = x.rename("output") # rename output tensor
        return x

def get_accuracy(model, loader):
    # changed to pass in our data!

    correct = 0
    total = 0
    for imgs, labels in loader:
        
        
        #############################################
        #To Enable GPU Usage
        # use_cuda is a flag!
        # we also check if the cuda library is available
        if torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()
        #############################################
        
        
        output = model(imgs)
        
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def get_model_name(name, batch_size, learning_rate, epoch):
    """ Generate a name for the model consisting of all the hyperparameter values

    Args:
        config: Configuration object containing the hyperparameters
    Returns:
        path: A string with the hyperparameter name and value concatenated
    """
    path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(name,
                                                   batch_size,
                                                   learning_rate,
                                                   epoch)
    return path

"""training code"""

def train(model, train_dataset, val_dataset, batch_size=64, num_epochs=10, learning_rate=0.001):
    torch.manual_seed(10)
    ImageFile.LOAD_TRUNCATED_IMAGES = True

    
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)

    train_acc = np.zeros(num_epochs)
    val_acc = np.zeros(num_epochs)

    # training
    print ("Training Started...")
    n = 0
    for epoch in range(num_epochs):
        total_train_loss = 0.0
        total_train_err = 0.0
        total_images = 0
        for imgs, labels in iter(train_loader):
            
            if torch.cuda.is_available():
              imgs = imgs.cuda()
              labels = labels.cuda()

            out = model(imgs)      # forward pass
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch
            n += 1          
        
        # track accuracy
        train_acc[epoch] = get_accuracy(model, train_loader)
        val_acc[epoch] = get_accuracy(model, val_loader)

        print(("Epoch {}: Train acc: {} | " + "Validation acc: {}").format(epoch, train_acc[epoch], val_acc[epoch]))

        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)
        torch.save(model.state_dict(), model_path)
            
    epochs = np.arange(1, num_epochs + 1)
    
    return train_acc, val_acc, epochs

"""# New Section"""
file_dir = os.getcwd()+'\\FinalDataset'

# define the transforms to be applied to the images
transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])

pics = torchvision.datasets.ImageFolder(file_dir, transform=transform)

# split into training, validation, and testing sets (60,20,20)
train_size = int(0.60 * len(pics))
val_size = int(0.20 * len(pics))
test_size = len(pics) - train_size - val_size
train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(pics, [train_size, val_size, test_size])

# create data loaders for each of the datasets
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=30, num_workers=1, shuffle=True)
val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=30, num_workers=1, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=30, num_workers=1, shuffle=True)

classes = []
for folder in os.scandir(file_dir):
 classes.append(folder.name)

classes.sort()

import multiprocessing
if __name__ == '__main__':
    multiprocessing.freeze_support()
# obtain one batch of training images
    dataiter = iter(train_loader)
    images, labels = next(dataiter)
    images = images.numpy() # convert images to numpy for display

    # plot the images in the batch, along with the corresponding labels
    fig = plt.figure(figsize=(25, 4))
    
    for idx in np.arange(30):
        ax = fig.add_subplot(3, 10, idx+1, xticks=[], yticks=[])
        plt.imshow(np.transpose(images[idx], (1, 2, 0)))
        ax.set_title(classes[labels[idx]])
    plt.show()



    cnnModel = CNetwork()

    train(cnnModel,train_dataset, val_dataset,batch_size=128,num_epochs=10)

    print(get_accuracy(cnnModel, test_loader))