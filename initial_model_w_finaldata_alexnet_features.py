# -*- coding: utf-8 -*-
"""Initial Model w finaldata AlexNet features

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZNv-gYKUEuTqgaK7XloKniXnwYPj8kuB

# import & mount
"""

import matplotlib
import matplotlib.pyplot as plt  # Most common visualization package that a lot of others are based on

import numpy as np  # Common package for numerical methods
import pandas as pd  # Common package for data storeage/manipulation
import seaborn as sns  # Common package for statistical visualizations
import datetime

# from IPython.display import SVG
# from graphviz import Source

# Import useful packages from sklearn
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.tree import export_graphviz
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_validate
from sklearn.linear_model import LogisticRegressionCV
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.feature_selection import SelectKBest, f_classif
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, recall_score
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix


# Torch and Time!
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms

# Import portion of a package
import scipy.stats as stats
from sklearn.impute import SimpleImputer as Imputer  # Specific function from common machine learning package

import seaborn as sns

from PIL import ImageFile

import torchvision.models
alexnet = torchvision.models.alexnet(pretrained=True)
import os
import multiprocessing

import warnings

warnings.filterwarnings('ignore')


"""#CNN for the AlexNet Features"""

class AlexClassifier(nn.Module):
    # Taken largely from Tut 3a
    def __init__(self):
        super(AlexClassifier, self).__init__()
        self.name = "Alex"
        self.fc1 = nn.Linear(256 * 6 * 6, 1024) 
        self.fc2 = nn.Linear(1024, 65)

    def forward(self, x):
        x = x.view(-1, 256 * 6 * 6)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x  

class ANN(nn.Module):
  def __init__(self):
    super(ANN, self).__init__()
    self.name = 'ANN'
    self.layer1 = nn.Linear(256*6*6, 500) #take alexnet features as input
    self.layer2 = nn.Linear(500, 250)
    self.layer3 = nn.Linear(250, 65)
  def forward(self, x):
    x = x.view(-1, 256*6*6)
    x = F.relu(self.layer1(x))
    x = F.relu(self.layer2(x))
    x = self.layer3(x)
    return x


def get_accuracy(model, loader):
    # changed to pass in our data!

    correct = 0
    total = 0
    for imgs, labels in loader:
        
        
        #############################################
        #To Enable GPU Usage
        # use_cuda is a flag!
        # we also check if the cuda library is available
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()
        #############################################
        
        
        output = model(imgs)
        
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def get_model_name(name, batch_size, learning_rate, epoch):
    """ Generate a name for the model consisting of all the hyperparameter values

    Args:
        config: Configuration object containing the hyperparameters
    Returns:
        path: A string with the hyperparameter name and value concatenated
    """
    path = "model_{0}_bs{1}_lr{2}_epoch{3}".format(name,
                                                   batch_size,
                                                   learning_rate,
                                                   epoch)
    return path

"""training code"""

# weird mishmash of tut 3a and lab 2 code!
# TRIANING CODE!

def train(model, train_loader, val_loader, batch_size=64, learning_rate = 0.005, num_epochs=30, momentum=0.9):
    print("Start")
    torch.manual_seed(1000)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum) #Try changing maybe

    iters, losses, train_acc, val_acc = [], [], [], []

    print("Start Training")
    # training
    n = 0 # the number of iterations
    ########################################################################
    # Train the network
    start_time = time.time()
    for epoch in range(num_epochs):
        for imgs, labels in iter(train_loader):
          
            #############################################
            #To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
                imgs = imgs.cuda()
                labels = labels.cuda()
            #############################################
            
              
            out = model(imgs)             # forward pass
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch

            # save the current training information
            iters.append(n)
            losses.append(float(loss)/batch_size)             # compute *average* loss
            n += 1
        #print("Epoch Complete")

        train_acc.append(get_accuracy(model, train_loader)) # compute training accuracy 
        val_acc.append(get_accuracy(model, val_loader))  # compute validation accuracy
        print(("Epoch {}: Train acc: {} |"+
        "Validation acc: {}").format(
            epoch + 1,
            train_acc[epoch],
            val_acc[epoch]))
        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)
        torch.save(model.state_dict(), model_path)   
        print("Epoch Time: {:.2f} seconds".format(time.time() - start_time))
        start_time = time.time()
    print('Finished Training')
    # Write the train/test loss/err into CSV file for plotting later
    epochs = np.arange(1, num_epochs + 1)

    # plotting

    epochs_range = range(1, num_epochs + 1)

    plt.title("Training Curve")
    plt.plot(iters, losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()

    plt.title("Training Curve")
    plt.plot(epochs_range, train_acc, label="Train")
    plt.plot(epochs_range, val_acc, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Training Accuracy")
    plt.legend(loc='best')
    plt.show()

    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))

if __name__ == '__main__':
    multiprocessing.freeze_support()
    path = os.getcwd()+'\\Alex_Net_Features_FinalDataset\\train'

    new_path = os.getcwd()+'\\Alex_Net_Features_FinalDataset'
    train_path = new_path + '\\train'
    val_path = new_path + '\\val'
    test_path = new_path + '\\test'

    classes = []
    
    for folder in os.scandir(path):
        classes.append(folder.name)
 
    s = []
    for folder in os.scandir(test_path):
        s.append(folder.name)
  
    
    

    use_cuda = True

    batch_size = 40

    alex_train_data = torchvision.datasets.DatasetFolder(train_path, loader=torch.load, extensions=('.tensor'))
    alex_train_loader = torch.utils.data.DataLoader(alex_train_data, batch_size=batch_size, num_workers=1, shuffle=True)

    alex_val_data = torchvision.datasets.DatasetFolder(val_path, loader=torch.load, extensions=('.tensor'))
    alex_val_loader = torch.utils.data.DataLoader(alex_val_data, batch_size=batch_size, num_workers=1, shuffle=True)


    alex_test_data = torchvision.datasets.DatasetFolder(test_path, loader=torch.load, extensions=('.tensor'))
    alex_test_loader = torch.utils.data.DataLoader(alex_test_data, batch_size=batch_size, num_workers=1, shuffle=True)

    alex = AlexClassifier()
    cnn = ANN()
    if use_cuda and torch.cuda.is_available():
        print("Using Cuda (GPU!)")
        cnn.cuda()
    
    train(model = cnn, batch_size = batch_size, train_loader = alex_train_loader, val_loader = alex_val_loader, num_epochs=10)

    print("DONE!")